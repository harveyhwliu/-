面对分布式消息系统的三大难题，对比阿里RocketMQ，我厂的TubeMQ有哪些优势？

分布式消息系统三大难题，顺序，重复和事务：
顺序：
我们可以这样去理解顺序性，生产顺序性，存储顺序性，消费顺序性。生产顺序性，这个可以实现，按照业务逻辑的先后去生产消息。存储顺序性，在分布式网络环境下，全局顺序是不可能的，从生产节点到达存储节点，中间经过网络，可能存在的延时、抖动，导致到达时间不确定。消费顺序性，存储顺序和消费节点的消费方式决定了孤立的去讨论消费顺序性是没有意义的，生产顺序和存储顺序不一致，存储顺序和最终到达消费节点的顺序也不一致，达到消费节点的顺序和最终消费完的顺序（异步消费）也是不一致的。

重复：
消费重复的问题，涉及到Exactly-Once。在消息系统中，消息的投递涉及到三种情况，至少投递一次(可能多次)、至多一次(可能0次，即丢失消息)、刚好一次即完成正确投递。
（1）至多一次在实际的消息系统中几乎没有被采用，在设计阶段，消息丢失的方案是不可能被接受的。
（2）至少投递一次，业务处理可能失败，失败就会有重试，那么极有可能存在消息重复，对于重复问题，消息系统去重在数据量比较大的情况下成本太高，我们可以在业务端解决，做好消费幂等，消费端允许重复消费，所以绝大部分消息系统是存在消息重复的可能性的。
（3）刚好一次，在分布式环境下，严格意义的Exactly-Once是不可能的，CAP、FLP不可能性、拜占庭将军问题.....等理论都告诉我们，在分布式系统中，不可能做到严格一致。但我们发现Kafka声称做到了Exactly-Once，https://cwiki.apache.org/confluence/display/KAFKA/KIP-98+-+Exactly+Once+Delivery+and+Transactional+Messaging，实际看了之后发现Kafka不过是结合软件工程和实际应用，做了一下概念上的置换。不过这也是很大的进步，毕竟人间支持transaction，朝着数学上的Exactly-Once更近了一步。

事务：
提到分布式事务，不得不提2阶段提交协议(Two-Phase Commit)，
Kafka能支持分布式事务，保证微服务事务的完整性，关键是将偏移量和你要保存的状态通过JDBC事务或者JTA事务保存到数据库，失败恢复时从这个偏移量开始从卡夫卡中重新读取，保证了消息和你的业务状态数据的一致性，由此Kafka的事务特性是依赖JDBC事务或者JTA事务的，依赖更多的组件。

我们来看看RocketMQ是怎么做到事务性消息的，生产者TransactionMQProducer涉及到2个角色：本地事务执行器（代码中的TransactionExecuterImpl）、服务器回查客户端Listener（代码中的TransactionCheckListener）。如果事务消息发送到MQ上后，会回调本地事务执行器；但是此时事务消息是prepare状态，对消费者还不可见，需要本地事务执行器返回RMQ一个确认消息。只有当确认完之后，才会将消息的状态由消费端不可见的prepare状态更新为消费者端可见的commied状态，我们分析发现，RocketMQ多了prepare状态和确认(check listener回查机制)环节，但不依赖JDBC事务或者JTA事务。

这也是RocketMQ在消息事务方面，吞吐量高于Kafka的原因。

最终的问题是：在这三个方面TubeMQ(https://github.com/Tencent/TubeMQ)是怎么做的，对比Kafka和RocketMQ，TubeMQ有哪些优势？能否提供数据和展示对应的核心代码？


回答1：
我负责这个项目，我回答你这个问题吧，相关问题外网同学也有问，我根据１１月７日Ｔｅｃｈｏ大会上的材料进行过问题回应：https://www.zhihu.com/question/346540432/answer/889620437

TubeMQ属于分布式消息队列，顺序性与Kafka一致，生产消费幂等系统只保证消费尽可能的不丢但不保证不多，去重由业务侧根据数据全局ＩＤ进行去重处理，不支持事务；同时，和其他ＭＱ比，即使同是大数据场景使用，数据丢失率严重情况下会比同场景的其他ＭＱ按Topic计算多２Ｍ左右，按照包１Ｋ大小，消息１Ｋ条刷盘率计算，丢失率占比相比其他ＭＱ还会多２％以内。

这就是TubeMQ的基本盘，大家可能更是疑惑，这样看TubeMQ如此没有优势，不值得去用，为什么甚至还被开源到Apache，为什么？因为这里除了你所说的３点外，还有一些问题大家还不太了解：

每种ＭＱ都有适用范围，在大数据场景下对ＭＱ有什么要求？高吞吐低延时，系统尽可能稳定，成本尽可能低。把上面的文字换成数字是什么样子？　这里有一个2019 年 11 月 8 日 LinkIn发表的一篇使用Kafka的实践总结image.png（https://www.infoq.cn/article/JOAbODsxj5L5jE3twFeG）
７万亿的数据量用了４０００多台机器，这里没有写机型，没有关系，我还知道另外一家国内公司，７万亿用了多少机器，用了１５００台万兆机，大家知道我们公司里，大数据环境３５万亿数据量情况多少台机器？　１５００台万兆机（仍有缓冲ｂｕｆｆｅｒ）。

我们采用自己设计的存储方案，以及自己设计的管控方式，用高２％的数据丢失率代价，达到了４到５倍的吞吐量，算作钱的话，如果３５万亿的数据，按照外部使用数据，即使仅考虑服务器资源，用TubeMQ可以给公司省了几个亿；然后大家知道我们系统的运营人力成本又有多高吗？２个非全职的系统运维人员，以往还只有１个人。

省钱，成本低，稳定性好，性能强，这个是TubeMQ的特点：TubeMQ适合大数据场景使用，针对大数据场景进行的自研，适合要求高稳定性，高吞吐，低时延，但又要求低成本的海量数据传输场景，如果你要做秒级监控，海量数据上报，实时广告推荐，流式数据处理等；相比Kafka，RocketMQ这类通用型ＭＱ，在通用场景，比如我要做交互，要做事务，要做定时任务等，TubeMQ没有优势，甚至我还建议大家使用这种通用型的ＭＱ会更合适一点；但在大数据领域，数据量到百亿，千亿，上万亿，甚至更高几十万亿场景，按照我们近２年对外部开源ＭＱ的评估，TubeMQ仍是最佳实践。

然后，项目都对外开源了，文档也已提供，大家随便分析都可以，如果能提供ｉｓｓｕｅ或者ｐｒ进行项目改进，非常期待。

回答2：
问题问的很有水平，楼上团队的Goson同学也做了非常详细的回复。这里其实涉及到分布式系统设计的基础性问题，即如何在性能（包括性价比，运维成本）与消息的语义完备性上做取舍。从使用场景上看，大数据消息中间件还是有别于传统的企业消息中间件，数据量级带来的压力与成本必然要求我们在极致的性能上面越走越远。TubeMQ主打高性能，与运维的简单化；另一个产品Hippo则主打复杂的消息语义与功能（顺序，exactly-once, 多副本等）。实践结果表明，前者的业务使用量是后者的10倍左右，因为数据吞吐量、系统的健壮性以及运维的简化在很多场景上更为刚需。
随着TubeMQ的开源（成为Apache项目），我们也会借助外部社区的力量去尝试覆盖更多、更丰富的场景，包括：把Hippo的很多优点复用到TubeMQ上来，并借助外部贡献者的经验与力量去结合Kafka, Pulsar等优势特性，最终把TubeMQ打造成一款可咸可甜，内部支持好万亿级高价值的业务，外部收获良好技术口碑的开源产品。这是我们团队努力的方向与使命！也欢迎内部有经验和意愿的小伙伴们一起加入，来开源协同打造属于鹅厂的对外开源技术名片项目 - Apache TubeMQ。
